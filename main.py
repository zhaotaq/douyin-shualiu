#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŠ–éŸ³åˆ·é‡æ‰¹é‡æäº¤ç³»ç»Ÿ
ç®€æ´ç‰ˆä¸»ç¨‹åº
"""

from douyin_batch_submitter_v2 import DouyinBatchSubmitterV2
import json
import time
from datetime import datetime
import subprocess
import requests
import os
import base64
import yaml
import random

def load_urls_from_file(filename: str = "douyin_urls.txt") -> list:
    """ä»æ–‡ä»¶åŠ è½½URLåˆ—è¡¨"""
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            urls = [line.strip() for line in f if line.strip()]
        return urls
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶ {filename} ä¸å­˜åœ¨")
        return []

def save_urls_to_file(urls: list, filename: str = "douyin_urls.txt"):
    """ä¿å­˜URLåˆ—è¡¨åˆ°æ–‡ä»¶"""
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            for url in urls:
                f.write(url + '\n')
        print(f"ğŸ“ é“¾æ¥å·²ä¿å­˜åˆ° {filename}")
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {e}")

def quick_test():
    """å¿«é€Ÿæµ‹è¯•åŠŸèƒ½"""
    print("ğŸš€ å¿«é€Ÿæµ‹è¯•æ¨¡å¼")
    print("=" * 40)
    
    submitter = DouyinBatchSubmitterV2()
    
    # æµ‹è¯•è¿æ¥
    if submitter.test_connection():
        print("âœ… APIè¿æ¥æ­£å¸¸")
    else:
        print("âŒ APIè¿æ¥å¼‚å¸¸")
        return False
    
    # æµ‹è¯•é“¾æ¥
    test_url = input("è¯·è¾“å…¥æµ‹è¯•é“¾æ¥ï¼ˆå›è½¦ä½¿ç”¨é»˜è®¤ï¼‰: ").strip()
    if not test_url:
        test_url = f"https://www.douyin.com/video/75023406983692{datetime.now().strftime('%H%M%S')}"
    
    print(f"ğŸ“¤ æµ‹è¯•é“¾æ¥: {test_url}")
    
    success, message, order_info = submitter.submit_single_url(test_url)
    
    if success:
        print("âœ… æäº¤æˆåŠŸï¼")
        print("ğŸ“‹ è®¢å•ä¿¡æ¯:")
        for key, value in order_info.items():
            if key != 'response':
                print(f"   {key}: {value}")
        return True
    else:
        print(f"ğŸ“‹ æäº¤ç»“æœ: {message}")
        
        if "é‡å¤æäº¤" in message or "å·²é¢†å–è¿‡" in message:
            print("â„¹ï¸ è¿™è¯´æ˜APIå·¥ä½œæ­£å¸¸ï¼Œåªæ˜¯æœ‰é‡å¤/é™åˆ¶")
            return True
        else:
            print("âŒ å¯èƒ½å­˜åœ¨å…¶ä»–é—®é¢˜")
            return False

def batch_submit(mihomo_path, config_path, proxy_port, api_port, group_name, all_nodes, urls, delay_min, delay_max):
    """æ‰¹é‡æäº¤åŠŸèƒ½"""
    print("ğŸš€ æ‰¹é‡æäº¤æ¨¡å¼")
    print("=" * 40)
    
    print(f"ğŸ“‹ å…±æœ‰ {len(urls)} ä¸ªé“¾æ¥å¾…æäº¤")
    
    print(f"\nğŸš€ å¼€å§‹æ‰¹é‡æäº¤...")
    
    # Estimate total time based on delay
    avg_delay = (delay_min + delay_max) / 2
    estimated_min_time = len(urls) * avg_delay
    print(f'â³ ä¼°ç®—æœ€å°å®Œæˆæ—¶é—´ (ä»…è€ƒè™‘å»¶è¿Ÿ): çº¦ {estimated_min_time:.1f} ç§’')

    results = []
    used_nodes_in_batch = set() # Set to keep track of nodes successfully used in this batch

    for i, url in enumerate(urls, 1):
        # Print progress
        print(f'\n--- å¤„ç†è¿›åº¦: {i}/{len(urls)} --- URL: {url} ---')

        tried_nodes = set()
        success = False
        message = ''
        order_info = {}
        node_used_for_success = None
        
        # Attempt to submit with different nodes, up to 10 times or until successful/other error
        max_attempts = 10
        attempt_count = 0
        
        # Filter out used nodes for this URL attempt block
        available_nodes_for_url = [node for node in all_nodes if node not in used_nodes_in_batch]
        random.shuffle(available_nodes_for_url)

        # Use a while loop to control attempts based on result
        while attempt_count < max_attempts and available_nodes_for_url:
            attempt_count += 1
            
            # Select a node from the filtered and shuffled list
            # We shuffle the list once before the loop, so just pick the next available one
            node = available_nodes_for_url.pop(0)
            tried_nodes.add(node) # Keep track of nodes tried in total for this URL
            
            print(f'ğŸ”„ å°è¯•èŠ‚ç‚¹ ({attempt_count}/{max_attempts}) for {url}: {node}')

            mihomo_proc = None # Initialize mihomo_proc for this attempt
            
            try:
                # Start mihomo for this attempt
                print(f'ğŸš€ å¯åŠ¨mihomoä»£ç†å†…æ ¸ for {url} with {node}...')
                mihomo_proc = start_mihomo(mihomo_path, config_path)
                print(f'â³ ç­‰å¾…ä»£ç†APIç«¯å£å¯åŠ¨ for {url} with {node}...')
                if not wait_mihomo_api(api_port):
                    print(f'âŒ mihomoå¯åŠ¨å¤±è´¥ for {url} with {node}ï¼Œå°è¯•ä¸‹ä¸€ä¸ªèŠ‚ç‚¹')
                    # Ensure mihomo is terminated before continuing
                    if mihomo_proc:
                        mihomo_proc.terminate()
                        time.sleep(2)
                    continue # Continue to next node attempt
                print(f'âœ… mihomoå·²å¯åŠ¨ï¼ŒAPIå¯ç”¨ for {url} with {node}')
                
                try:
                    # Switch node - Use the selected node
                    print(f'ğŸ”„ åˆ‡æ¢èŠ‚ç‚¹ to {node} for {url}...')
                    switch_random_node_main_group(api_port, group_name, [node])
                    print(f'âœ… èŠ‚ç‚¹ {node} åˆ‡æ¢æˆåŠŸ for {url}')
                except Exception as e:
                    print(f'âŒ èŠ‚ç‚¹åˆ‡æ¢å¤±è´¥ ({node}) for {url}: {e}ï¼Œå°è¯•ä¸‹ä¸€ä¸ªèŠ‚ç‚¹')
                    # Ensure mihomo is terminated before continuing
                    if mihomo_proc:
                        mihomo_proc.terminate()
                        time.sleep(2)
                    continue # Continue to next node attempt

                # å¯ç”¨èŠ‚ç‚¹ï¼Œæäº¤åˆ·æµ
                submitter = DouyinBatchSubmitterV2(base_url="https://longsiye.nyyo.cn")
                
                submit_success = False
                submit_message = ''
                submit_order_info = {}
                last_error_message = '' # Variable to store the last error message for the URL

                try:
                    print(f'ğŸ“¤ ä½¿ç”¨èŠ‚ç‚¹ {node} æäº¤é“¾æ¥: {url}')
                    submit_success, submit_message, submit_order_info = submitter.submit_single_url(url)
                    
                    # If submission was successful, set success and break the node loop
                    if submit_success:
                        success = True # Mark overall success for this URL
                        message = submit_message
                        order_info = submit_order_info
                        node_used_for_success = node
                        used_nodes_in_batch.add(node) # Add successfully used node to the set
                        print(f'âœ… æäº¤æˆåŠŸ for {url}ï¼ä½¿ç”¨èŠ‚ç‚¹: {node}')
                        # Terminate mihomo before breaking
                        if mihomo_proc:
                            mihomo_proc.terminate()
                            time.sleep(2)
                        break # Success, break the node attempt loop for this URL
                        
                    # If submission failed but is a known transient error, try next node
                    elif "æ‚¨ä»Šå¤©å·²é¢†å–è¿‡" in submit_message or "é‡å¤æäº¤" in submit_message:
                        print(f'â„¹ï¸ èŠ‚ç‚¹ {node} å·²é¢†å–è¿‡/é‡å¤æäº¤ for {url}ï¼Œå°è¯•ä¸‹ä¸€ä¸ªèŠ‚ç‚¹...')
                        last_error_message = submit_message # Store this message
                        # Terminate mihomo before continuing
                        if mihomo_proc:
                            mihomo_proc.terminate()
                            time.sleep(2)
                        # continue # Continue the while loop to try the next node - continue is implied if no break/return
                        
                    else:
                        # Other API failure, record message and potentially break
                        # Modified log message to escape backslashes
                        print(f'âŒ æäº¤å¤±è´¥ ({node}) for {url}: {submit_message}ï¼Œå°è¯•ä¸‹ä¸€ä¸ªèŠ‚ç‚¹...') 
                        last_error_message = submit_message # Store this message
                        # Terminate mihomo before potentially breaking
                        if mihomo_proc:
                            mihomo_proc.terminate()
                            time.sleep(2)
                        # continue # Continue is implied unless max attempts reached or no nodes left

                except requests.exceptions.SSLError as ssl_error:
                    # Modified log message to escape backslashes
                    print(f'âŒ æäº¤æ—¶å‘ç”ŸSSLè¿æ¥é”™è¯¯ ({node}) for {url}: {ssl_error}ï¼Œå°è¯•ä¸‹ä¸€ä¸ªèŠ‚ç‚¹...') 
                    last_error_message = f'SSLè¿æ¥é”™è¯¯ ({node}): {ssl_error}' # Store error message
                    # Ensure mihomo is terminated before continuing
                    if mihomo_proc:
                        mihomo_proc.terminate()
                        time.sleep(2) # Short delay after exception
                    continue # Continue the while loop to try the next node
                    
                except Exception as api_error:
                     # Catch other potential exceptions from submit_single_url
                     print(f'âŒ æäº¤æ—¶å‘ç”Ÿå…¶ä»–å¼‚å¸¸ ({node}) for {url}: {api_error}ï¼Œåœæ­¢å°è¯•è¯¥é“¾æ¥çš„å…¶ä»–èŠ‚ç‚¹') # Modified log
                     last_error_message = f'æäº¤å¼‚å¸¸ ({node}): {api_error}' # Store error message
                     # Terminate mihomo
                     if mihomo_proc:
                        mihomo_proc.terminate()
                        time.sleep(2) # Short delay after exception
                     # This is a more critical error, break the node attempt loop for this URL
                     break # Break the node attempt loop for this URL

                # After a submission attempt (success, transient failure, or handled exception), mihomo should be terminated.
                # The terminate is now handled within the try/except blocks or before break/continue.

            except Exception as e:
                # Catch exceptions during mihomo start, switch, or before submission try block
                print(f'âŒ å¤„ç†èŠ‚ç‚¹æ—¶å¼‚å¸¸ ({node}) for {url}: {e}ï¼Œå°è¯•ä¸‹ä¸€ä¸ªèŠ‚ç‚¹') # Modified log
                last_error_message = f'å¤„ç†èŠ‚ç‚¹å¼‚å¸¸ ({node}): {e}' # Store error message
                # Ensure mihomo is terminated before continuing
                if mihomo_proc:
                    mihomo_proc.terminate()
                    time.sleep(2) # Short delay after exception
                continue # Continue the while loop to try the next node

        # End of node attempt loop for the current URL
        # Check if submission was successful with any node
        if success:
            print(f"âœ… URL {url} æœ€ç»ˆæäº¤æˆåŠŸ (ä½¿ç”¨èŠ‚ç‚¹: {node_used_for_success})")
        else:
            # If loop finished and not success, report the last recorded error or a general failure
            # Modified log message to escape backslashes
            final_message = last_error_message if last_error_message else f'âŒ URL {url} åœ¨æ‰€æœ‰ {attempt_count} æ¬¡å°è¯•åä»ç„¶å¤±è´¥ã€‚æ— å…·ä½“é”™è¯¯ä¿¡æ¯ã€‚'
            print(f"âŒ URL {url} æœ€ç»ˆæäº¤å¤±è´¥ (åŸå› : {final_message})")
            message = final_message # Update the message for the result object

        # Record the result for this URL
        result = {
            'url': url,
            'success': success,
            'message': message, # Use the final message
            'order_info': order_info,
            'submit_time': datetime.now().isoformat(),
            'node_used': node_used_for_success # Record node only on final success
        }
        results.append(result)
        if i < len(urls):
            delay = random.uniform(delay_min, delay_max)
            print(f'â³ ç­‰å¾… {delay:.1f} ç§’...')
            time.sleep(delay)

    # ç»Ÿè®¡
    success_count = sum(1 for r in results if r['success'])
    total_count = len(results)
    print(f"\nğŸ“Š æäº¤å®Œæˆ:")
    print(f"âœ… æˆåŠŸ: {success_count}/{total_count}")
    if total_count > 0:
        print(f"ğŸ“ˆ æˆåŠŸç‡: {(success_count/total_count*100):.1f}%")
    else:
        print("ğŸ“ˆ æˆåŠŸç‡: 0.0%ï¼ˆæ— æœ‰æ•ˆæäº¤ï¼‰")
    
    print('ğŸ›‘ æ‰¹é‡æäº¤ä»»åŠ¡å®Œæˆ') # Update message

    # Save results to a JSON file
    try:
        existing_results = []
        if os.path.exists('submission_results.json'):
            with open('submission_results.json', 'r', encoding='utf-8') as f:
                try:
                    existing_results = json.load(f)
                except json.JSONDecodeError:
                    print("âš ï¸ ç°æœ‰ submission_results.json æ–‡ä»¶å†…å®¹æ— æ•ˆï¼Œå°†è¦†ç›–ã€‚")
                    existing_results = []

        existing_results.extend(results)

        with open('submission_results.json', 'w', encoding='utf-8') as f:
            json.dump(existing_results, f, indent=4, ensure_ascii=False)
        print("âœ… è¯¦ç»†æäº¤ç»“æœå·²ä¿å­˜åˆ° submission_results.json")
    except Exception as e:
        print(f"âŒ ä¿å­˜ç»“æœåˆ°æ–‡ä»¶å¤±è´¥: {e}")

def download_and_generate_config(sub_url, config_path, proxy_port, api_port):
    resp = requests.get(sub_url)
    try:
        content = base64.b64decode(resp.text).decode()
    except Exception:
        content = resp.text  # å¯èƒ½ç›´æ¥æ˜¯yaml
    config = yaml.safe_load(content)
    config['port'] = proxy_port
    config['external-controller'] = f'127.0.0.1:{api_port}'
    # ä¿ç•™æ‰€æœ‰åˆ†ç»„ï¼Œè‡ªåŠ¨è¯†åˆ«Selectoråˆ†ç»„
    with open(config_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, allow_unicode=True)

def start_mihomo(mihomo_path, config_path):
    proc = subprocess.Popen([
        mihomo_path,
        '-d', '.',
        '-f', config_path
    ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    return proc

def wait_mihomo_api(api_port, timeout=30):
    for _ in range(timeout):
        try:
            r = requests.get(f'http://127.0.0.1:{api_port}/proxies', timeout=1)
            if r.status_code == 200:
                return True
        except Exception:
            time.sleep(1)
    return False

def get_main_group_and_all_nodes(api_port):
    r = requests.get(f'http://127.0.0.1:{api_port}/proxies')
    data = r.json()
    # å…¼å®¹é¡¶å±‚ä¸º{"proxies": {...}}çš„ç»“æ„
    if 'proxies' in data:
        data = data['proxies']
    # è‡ªåŠ¨è¯†åˆ«ç¬¬ä¸€ä¸ªæœ‰allå­—æ®µä¸”ä¸æ˜¯providerçš„åˆ†ç»„ä¸ºä¸»åˆ†ç»„
    group_names = [k for k, v in data.items() if v.get('all') and not v.get('type', '').lower().endswith('provider')]
    if not group_names:
        raise RuntimeError('æœªæ‰¾åˆ°ä»»ä½•åˆ†ç»„')
    main_group = group_names[0]
    # é€’å½’å±•å¼€æ‰€æœ‰çœŸå®èŠ‚ç‚¹
    def collect_nodes(group_name, visited=None):
        if visited is None:
            visited = set()
        if group_name in visited:
            return []
        visited.add(group_name)
        group = data.get(group_name, {})
        nodes = group.get('all') or []
        real_nodes = []
        for n in nodes:
            n_type = data.get(n, {}).get('type', '').lower()
            if n in data and n_type in ('selector', 'urltest', 'fallback'):
                real_nodes.extend(collect_nodes(n, visited))
            else:
                real_nodes.append(n)
        return real_nodes
    all_nodes = collect_nodes(main_group)
    if not all_nodes:
        raise RuntimeError('ä¸»åˆ†ç»„ä¸‹æœªæ‰¾åˆ°ä»»ä½•çœŸå®èŠ‚ç‚¹')
    return main_group, all_nodes

def switch_random_node_main_group(api_port, group_name, all_nodes):
    node = random.choice(all_nodes)
    resp = requests.put(f'http://127.0.0.1:{api_port}/proxies/{group_name}', json={'name': node})
    resp.raise_for_status()
    now = requests.get(f'http://127.0.0.1:{api_port}/proxies/{group_name}').json().get('now')
    if now != node:
        raise RuntimeError(f'åˆ‡æ¢èŠ‚ç‚¹å¤±è´¥: æœŸæœ›{node}, å®é™…{now}')
    return node

def is_node_available(proxy_port):
    proxies = {
        'http': f'http://127.0.0.1:{proxy_port}',
        'https': f'http://127.0.0.1:{proxy_port}',
    }
    try:
        resp = requests.get('https://longsiye.nyyo.cn', proxies=proxies, timeout=5, verify=False)
        return resp.status_code == 200
    except Exception:
        return False

def main():
    print('ğŸ¯ æŠ–éŸ³åˆ·é‡æ‰¹é‡æäº¤ç³»ç»Ÿï¼ˆè‡ªåŠ¨ä»£ç†é›†æˆç‰ˆï¼‰')
    print('=' * 40)
    config_path = './clash_config.yaml'
    mihomo_path = './mihomo-windows-amd64.exe'
    proxy_port = 9950
    api_port = 9900
    # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(config_path):
        sub_url = input('è¯·è¾“å…¥ä»£ç†è®¢é˜…é“¾æ¥: ').strip()
        print('â¬ æ­£åœ¨ä¸‹è½½è®¢é˜…å¹¶ç”Ÿæˆé…ç½®...')
        download_and_generate_config(sub_url, config_path, proxy_port, api_port)
    else:
        # æ£€æŸ¥å¹¶ä¿®æ­£ç«¯å£
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        changed = False
        if config.get('mixed-port') != proxy_port:
            config['mixed-port'] = proxy_port
            changed = True
        if config.get('external-controller') != f'127.0.0.1:{api_port}':
            config['external-controller'] = f'127.0.0.1:{api_port}'
            changed = True
        if changed:
            with open(config_path, 'w', encoding='utf-8') as f:
                yaml.dump(config, f, allow_unicode=True)
            print(f'å·²è‡ªåŠ¨ä¿®æ­£é…ç½®æ–‡ä»¶ç«¯å£ä¸º {proxy_port}/{api_port}')
        else:
            print(f'æ£€æµ‹åˆ°å·²å­˜åœ¨é…ç½®æ–‡ä»¶ {config_path}ï¼Œå°†ç›´æ¥å¤ç”¨ã€‚')
    # è·å–æ‰€æœ‰èŠ‚ç‚¹ä¿¡æ¯ï¼ˆåªéœ€ä¸€æ¬¡ï¼‰
    print('ğŸš€ å¯åŠ¨mihomoè·å–èŠ‚ç‚¹ä¿¡æ¯...')
    mihomo_proc_init = start_mihomo(mihomo_path, config_path)
    print('â³ ç­‰å¾…ä»£ç†APIç«¯å£å¯åŠ¨...')
    if not wait_mihomo_api(api_port):
        print('âŒ mihomoå¯åŠ¨å¤±è´¥ï¼Œæ— æ³•è·å–èŠ‚ç‚¹åˆ—è¡¨')
        mihomo_proc_init.terminate()
        time.sleep(2)
        return # Exit main function
    print('âœ… mihomoå·²å¯åŠ¨ï¼ŒAPIå¯ç”¨ï¼Œæ­£åœ¨è·å–èŠ‚ç‚¹åˆ—è¡¨...')

    try:
        group_name, all_nodes = get_main_group_and_all_nodes(api_port)
        print(f'æ£€æµ‹åˆ°ä¸»åˆ†ç»„: {group_name}ï¼Œå…±{len(all_nodes)}ä¸ªçœŸå®èŠ‚ç‚¹')
    except Exception as e:
        print(f'âŒ è·å–èŠ‚ç‚¹ä¿¡æ¯å¤±è´¥: {e}')
        mihomo_proc_init.terminate()
        time.sleep(2)
        return # Exit main function
    finally:
        # Terminate the initial mihomo process used only for getting the node list
        mihomo_proc_init.terminate()
        time.sleep(2)

    # é€‰æ‹©åˆ·æµæ¨¡å¼
    urls = []
    print('è¯·è¾“å…¥æŠ–éŸ³è§†é¢‘é“¾æ¥ï¼ˆæ¯è¡Œä¸€ä¸ªï¼Œè¾“å…¥ç©ºè¡Œç»“æŸï¼‰:')
    while True:
        url = input('é“¾æ¥: ').strip()
        if not url:
            break
        urls.append(url)
    if not urls:
        print('âŒ æ²¡æœ‰å¯æäº¤çš„é“¾æ¥')
        return
    print(f'ğŸ“‹ å…±æœ‰ {len(urls)} ä¸ªé“¾æ¥å¾…æäº¤')
    delay_min = float(input('æœ€å°å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤3ï¼‰: ') or '3')
    delay_max = float(input('æœ€å¤§å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼Œé»˜è®¤8ï¼‰: ') or '8')
    confirm = input(f'\nç¡®è®¤æäº¤ {len(urls)} ä¸ªé“¾æ¥ï¼Ÿ(y/n): ').lower()
    if confirm != 'y':
        print('âŒ å·²å–æ¶ˆ')
        return
    
    # è°ƒç”¨æ‰¹é‡æäº¤å‡½æ•°ï¼Œä¼ å…¥å‚æ•°
    batch_submit(mihomo_path, config_path, proxy_port, api_port, group_name, all_nodes, urls, delay_min, delay_max)

if __name__ == "__main__":
    main() 